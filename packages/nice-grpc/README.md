# nice-grpc [![npm version][npm-image]][npm-url]

A Node.js gRPC library that is nice to you. Built on top of
[`grpc-js`](https://www.npmjs.com/package/@grpc/grpc-js).

<!-- TOC depthFrom:2 depthTo:5 -->

- [Features](#features)
- [Installation](#installation)
- [Usage](#usage)
  - [Compiling Protobuf files](#compiling-protobuf-files)
    - [Using `ts-proto`](#using-ts-proto)
    - [Using `google-protobuf`](#using-google-protobuf)
  - [Server](#server)
    - [Errors](#errors)
    - [Metadata](#metadata)
    - [Cancelling calls](#cancelling-calls)
    - [Server streaming](#server-streaming)
      - [Example: IxJS](#example-ixjs)
      - [Example: Observables](#example-observables)
    - [Client streaming](#client-streaming)
    - [Middleware](#middleware)
      - [Example: Logging](#example-logging)
      - [Example: Error handling](#example-error-handling)
      - [Example: Authentication](#example-authentication)
    - [Server Reflection](#server-reflection)
  - [Client](#client)
    - [Channels](#channels)
    - [Metadata](#metadata-1)
    - [Errors](#errors-1)
    - [Cancelling calls](#cancelling-calls-1)
    - [Deadlines](#deadlines)
    - [Server streaming](#server-streaming-1)
    - [Client streaming](#client-streaming-1)
    - [Middleware](#middleware-1)
      - [Example: Logging](#example-logging-1)
      - [Example: Timeouts](#example-timeouts)

<!-- /TOC -->
<!-- Generated by Markdown TOC -->
<!-- https://marketplace.visualstudio.com/items?itemName=AlanWalk.markdown-toc -->

## Features

- Written in TypeScript for TypeScript.
- Modern API that uses Promises and Async Iterables for streaming.
- Cancelling client and server calls using
  [`AbortSignal`](https://developer.mozilla.org/en-US/docs/Web/API/AbortSignal).
- Client and server middleware support via concise API that uses Async
  Generators.

## Installation

```
npm install nice-grpc @grpc/grpc-js
```

## Usage

### Compiling Protobuf files

The recommended way is to use
[`ts-proto`](https://github.com/stephenh/ts-proto).

#### Using `ts-proto`

Install necessary tools:

```
npm install protobufjs long
npm install --save-dev grpc-tools ts-proto
```

Given a Protobuf file `./proto/example.proto`, generate TypeScript code into
directory `./compiled_proto`:

```
./node_modules/.bin/grpc_tools_node_protoc \
  --ts_proto_out=./compiled_proto \
  --ts_proto_opt=outputServices=grpc-js \
  ./proto/example.proto
```

#### Using `google-protobuf`

Install necessary tools:

```
npm install google-protobuf
npm install --save-dev grpc-tools grpc_tools_node_protoc_ts @types/google-protobuf
```

Given a Protobuf file `./proto/example.proto`, generate JS code and TypeScript
definitions into directory `./compiled_proto`:

```
./node_modules/.bin/grpc_tools_node_protoc \
  --js_out=import_style=commonjs,binary:./compiled_proto \
  --ts_out=grpc_js:./compiled_proto \
  --grpc_out=grpc_js:./compiled_proto \
  ./proto/example.proto
```

### Server

Consider the following Protobuf definition:

```proto
syntax = "proto3";

package nice_grpc.example;

service ExampleService {
  rpc ExampleUnaryMethod(ExampleRequest) returns (ExampleResponse) {};
}

message ExampleRequest {
  // ...
}
message ExampleResponse {
  // ...
}
```

After compiling Protobuf file, we can write service implementation:

```ts
import {ServiceImplementation} from 'nice-grpc';
import {
  ExampleService,
  ExampleRequest,
  ExampleResponse,
} from './compiled_proto/example';

const exampleServiceImpl: ServiceImplementation<typeof ExampleService> = {
  async exampleUnaryMethod(request: ExampleRequest): Promise<ExampleResponse> {
    // ... method logic

    return ExampleResponse.fromPartial({});
  },
};
```

Alternatively, you can use classes:

```ts
class ExampleServiceImpl
  implements ServiceImplementation<typeof ExampleService> {
  async exampleUnaryMethod(request: ExampleRequest): Promise<ExampleResponse> {
    // ... method logic

    return ExampleResponse.fromPartial({});
  }
}
```

Now we can create and start a server that exposes our service:

```ts
import {createServer} from 'nice-grpc';
import {ExampleService} from './compiled_proto/example';

const server = createServer();

server.add(ExampleService, exampleServiceImpl);

await server.listen('0.0.0.0:8080');
```

Once we need to stop, gracefully shut down the server:

```ts
await server.shutdown();
```

#### Errors

To report an error to a client, use `ServerError`.

> Any thrown errors other than `ServerError` will result in client receiving
> error with status code `UNKNOWN`. Use server middleware for custom handling of
> uncaught errors.

See [gRPC docs](https://grpc.github.io/grpc/core/md_doc_statuscodes.html) for
the correct usage of status codes.

```ts
import {status} from '@grpc/grpc-js';
import {ServerError} from 'nice-grpc';

const exampleServiceImpl: ServiceImplementation<typeof ExampleService> = {
  async exampleUnaryMethod(request: ExampleRequest): Promise<ExampleResponse> {
    // ... method logic

    throw new ServerError(status.NOT_FOUND, 'Requested data does not exist');
  },
};
```

#### Metadata

A server receives client metadata along with request, and can send response
metadata in header and trailer.

```ts
const exampleServiceImpl: ServiceImplementation<typeof ExampleService> = {
  async exampleUnaryMethod(
    request: ExampleRequest,
    context: CallContext,
  ): Promise<ExampleResponse> {
    // read client metadata
    const someValue = context.metadata.get('some-key')[0] as string | undefined;

    // add metadata to header
    context.header.set('some-key', 'some-value');

    // ... method logic

    // add metadata to trailer
    context.trailer.set('some-key', 'some-value');

    return ExampleResponse.fromPartial({});
  },
};
```

#### Cancelling calls

A server receives
[`AbortSignal`](https://developer.mozilla.org/en-US/docs/Web/API/AbortSignal)
that gets aborted once the call is cancelled by the client, or due to a
deadline. You can use it to cancel any inner requests.

```ts
import fetch from 'node-fetch';

const exampleServiceImpl: ServiceImplementation<typeof ExampleService> = {
  async exampleUnaryMethod(
    request: ExampleRequest,
    context: CallContext,
  ): Promise<ExampleResponse> {
    const response = await fetch('http://example.com', {
      signal: context.signal,
    });

    // ...
  },
};
```

#### Server streaming

Consider the following Protobuf definition:

```proto
service ExampleService {
  rpc ExampleStreamingMethod(ExampleRequest)
    returns (stream ExampleResponse) {};
}
```

Service implementation defines this method as an Async Generator:

```ts
import {delay} from 'abort-controller-x';

const exampleServiceImpl: ServiceImplementation<typeof ExampleService> = {
  async *exampleStreamingMethod(
    request: ExampleRequest,
    context: CallContext,
  ): AsyncIterable<ExampleResponse> {
    for (let i = 0; i < 10; i++) {
      await delay(context.signal, 1000);

      yield ExampleResponse.fromPartial({});
    }
  },
};
```

##### Example: IxJS

```ts
import {range} from 'ix/asynciterable';
import {withAbort, map} from 'ix/asynciterable/operators';

const exampleServiceImpl: ServiceImplementation<typeof ExampleService> = {
  async *exampleStreamingMethod(
    request: ExampleRequest,
    context: CallContext,
  ): AsyncIterable<ExampleResponse> {
    yield* range(0, 10).pipe(
      withAbort(context.signal),
      map(() => ExampleResponse.fromPartial({})),
    );
  },
};
```

##### Example: Observables

```ts
import {Observable} from 'rxjs';
import {from} from 'ix/asynciterable';
import {withAbort} from 'ix/asynciterable/operators';

const exampleServiceImpl: ServiceImplementation<typeof ExampleService> = {
  async *exampleStreamingMethod(
    request: ExampleRequest,
    context: CallContext,
  ): AsyncIterable<ExampleResponse> {
    const observable: Observable<ExampleResponse>;

    yield* from(observable).pipe(withAbort(context.signal));
  },
};
```

#### Client streaming

Given a client streaming method:

```proto
service ExampleService {
  rpc ExampleClientStreamingMethod(stream ExampleRequest)
    returns (ExampleResponse) {};
}
```

Service implementation method receives request as an Async Iterable:

```ts
const exampleServiceImpl: ServiceImplementation<typeof ExampleService> = {
  async exampleUnaryMethod(
    request: AsyncIterable<ExampleRequest>,
  ): Promise<ExampleResponse> {
    for await (const item of request) {
      // ...
    }

    return ExampleResponse.fromPartial({});
  },
};
```

#### Middleware

Server middleware intercepts incoming calls allowing to:

- Execute any logic before and after implementation methods
- Look into request, request metadata and response
- Interrupt a call before it reaches implementation by throwing a `ServerError`
- Catch implementation errors and return friendly `ServerError`s to a client
- Augment call context
- Modify response header and trailer metadata

Server middleware is defined as an Async Generator. The most basic no-op
middleware looks like this:

```ts
import {ServerMiddlewareCall, CallContext} from 'nice-grpc';

async function* middleware<Request, Response>(
  call: ServerMiddlewareCall<Request, Response>,
  context: CallContext,
) {
  return yield* call.next(call.request, context);
}
```

For unary and client streaming methods, the `call.next` generator yields no
items and returns a single response; for server streaming and bidirectional
streaming methods, it yields each response and returns void. By doing
`return yield*` we cover both cases. To handle these cases separately, we can
write a middleware as follows:

```ts
async function* middleware<Request, Response>(
  call: ServerMiddlewareCall<Request, Response>,
  context: CallContext,
) {
  if (!call.responseStream) {
    const response = yield* call.next(call.request, context);

    return response;
  } else {
    for await (const response of call.next(call.request, context)) {
      yield response;
    }

    return;
  }
}
```

To attach a middleware to a server, use a `server.use` method. Note that
`server.use` returns a new server instance.

```ts
const server = createServer().use(middleware1).use(middleware2);
```

A middleware that is attached first, will be invoked first.

You can also attach middleware per-service:

```ts
const server = createServer().use(middlewareA);

server.with(middlewareB).add(Service1, service1Impl);
server.with(middlewareC).add(Service2, service2Impl);
```

In the above example, `Service1` gets `middlewareA` and `middlewareB`, and
`Service2` gets `middlewareA` and `middlewareC`.

##### Example: Logging

Log all calls:

```ts
import {status} from '@grpc/grpc-js';
import {isAbortError} from 'abort-controller-x';

async function* loggingMiddleware<Request, Response>(
  call: ServerMiddlewareCall<Request, Response>,
  context: CallContext,
) {
  const {path} = call.definition;

  console.log('Server call', path, 'start');

  try {
    const result = yield* call.next(call.request, context);

    console.log('Server call', path, 'end: OK');

    return result;
  } catch (error) {
    if (error instanceof ServerError) {
      console.log('Server call', path, `end: ${status[error.code]}`);
    } else if (isAbortError(error)) {
      console.log('Server call', path, 'cancel');
    } else {
      console.log('Server call', path, `error: ${error?.stack}`);
    }

    throw error;
  }
}
```

##### Example: Error handling

Catch unknown errors and wrap them into `ServerError`s with friendly messages:

```ts
import {status} from '@grpc/grpc-js';
import {isAbortError} from 'abort-controller-x';

async function* errorHandlingMiddleware<Request, Response>(
  call: ServerMiddlewareCall<Request, Response>,
  context: CallContext,
) {
  try {
    return yield* call.next(call.request, context);
  } catch (error: unknown) {
    if (error instanceof ServerError || isAbortError(error)) {
      throw error;
    }

    let details = 'Unknown server error occurred';

    if (process.env.NODE_ENV === 'development') {
      details += `: ${error.stack}`;
    }

    throw new ServerError(status.UNKNOWN, details);
  }
}
```

##### Example: Authentication

Validate JSON Web Token (JWT) from request metadata and put its claims to
`CallContext`:

```ts
import {status} from '@grpc/grpc-js';
import createRemoteJWKSet from 'jose/jwks/remote';
import jwtVerify, {JWTPayload} from 'jose/jwt/verify';
import {JOSEError} from 'jose/util/errors';

const jwks = createRemoteJWKSet(
  new URL('https://example.com/.well-known/jwks.json'),
);

type AuthCallContextExt = {
  auth: JWTPayload;
};

async function* authMiddleware<Request, Response>(
  call: ServerMiddlewareCall<Request, Response, AuthCallContextExt>,
  context: CallContext,
) {
  const authorization = context.metadata.get('Authorization')[0];

  if (authorization == null) {
    throw new ServerError(
      status.UNAUTHENTICATED,
      'Missing Authorization metadata',
    );
  }

  const parts = authorization.toString().split(' ');

  if (parts.length !== 2 || parts[0] !== 'Bearer') {
    throw new ServerError(
      status.UNAUTHENTICATED,
      'Invalid Authorization metadata format. Expected "Bearer <token>"',
    );
  }

  const token = parts[1];

  const {payload} = await jwtVerify(token, jwks).catch(error => {
    if (error instanceof JOSEError) {
      throw new ServerError(status.UNAUTHENTICATED, error.message);
    } else {
      throw error;
    }
  });

  return yield* call.next(call.request, {
    ...context,
    auth: payload,
  });
}
```

Service implementation can then access JWT claims via call context:

```ts
const exampleServiceImpl: ServiceImplementation<
  typeof ExampleService,
  AuthCallContextExt
> = {
  async exampleUnaryMethod(
    request: ExampleRequest,
    context: CallContext & AuthCallContextExt,
  ): Promise<ExampleResponse> {
    const userId = context.auth.sub;

    // ...
  },
};
```

#### Server Reflection

See
[deeplay-io/nice-grpc-server-reflection](https://github.com/deeplay-io/nice-grpc-server-reflection).

### Client

Consider the following Protobuf definition:

```proto
syntax = "proto3";

package nice_grpc.example;

service ExampleService {
  rpc ExampleUnaryMethod(ExampleRequest) returns (ExampleResponse) {};
}

message ExampleRequest {
  // ...
}
message ExampleResponse {
  // ...
}
```

After compiling Protobuf file, we can create the client:

```ts
import {createChannel, createClient} from 'nice-grpc';
import {ExampleService} from './compiled_proto/example';

const channel = createChannel('localhost:8080');

const client = createClient(ExampleService, channel);
```

When creating a client, you can specify default call options for all methods, or
per-method. See [Example: Timeouts](#example-timeouts).

Call the method:

```ts
import {ExampleRequest, ExampleResponse} from './compiled_proto/example';

const response: ExampleResponse = await client.exampleUnaryMethod(
  ExampleRequest.fromPartial({}),
);
```

Once we've done with the client, close the channel:

```ts
channel.close();
```

#### Channels

By default, a channel uses insecure connection. The following are equivalent:

```ts
import {ChannelCredentials} from '@grpc/grpc-js';
import {createChannel} from 'nice-grpc';

createChannel('example.com:8080');
createChannel('http://example.com:8080');
createChannel('example.com:8080', ChannelCredentials.createInsecure());
```

To connect over TLS, use one of the following:

```ts
createChannel('https://example.com:8080');
createChannel('example.com:8080', ChannelCredentials.createSsl());
```

If port is omitted, it defaults to `80` for insecure connections, and `443` for
secure connections.

#### Metadata

Client can send request metadata and receive response header and trailer:

```ts
import {Metadata} from '@grpc/grpc-js';

const metadata = new Metadata();
metadata.set('key', 'value');

const response = await client.exampleUnaryMethod(
  ExampleRequest.fromPartial({}),
  {
    metadata,
    onHeader(header: Metadata) {
      // ...
    },
    onTrailer(trailer: Metadata) {
      // ...
    },
  },
);
```

#### Errors

Client calls may throw gRPC errors represented as `ClientError`, that contain
status code and description.

```ts
import {status} from '@grpc/grpc-js';
import {ClientError} from 'nice-grpc';

let response: ExampleResponse | null;

try {
  response = await client.exampleUnaryMethod(ExampleRequest.fromPartial({}));
} catch (error: unknown) {
  if (error instanceof ClientError && error.code === status.NOT_FOUND) {
    response = null;
  } else {
    throw error;
  }
}
```

#### Cancelling calls

A client call can be cancelled using
[`AbortSignal`](https://developer.mozilla.org/en-US/docs/Web/API/AbortSignal).

```ts
import AbortController from 'node-abort-controller';
import {isAbortError} from 'abort-controller-x';

const abortController = new AbortController();

client
  .exampleUnaryMethod(ExampleRequest.fromPartial({}), {
    signal: abortController.signal,
  })
  .catch(error => {
    if (isAbortError(error)) {
      // aborted
    } else {
      throw error;
    }
  });

abortController.abort();
```

#### Deadlines

You can specify a deadline for a client call using `Date` object:

```ts
import {status} from '@grpc/grpc-js';
import {ClientError} from 'nice-grpc';
import {addSeconds} from 'date-fns';

try {
  const response = await client.exampleUnaryMethod(
    ExampleRequest.fromPartial({}),
    {
      deadline: addSeconds(new Date(), 15),
    },
  );
} catch (error: unknown) {
  if (error instanceof ClientError && error.code === status.DEADLINE_EXCEEDED) {
    // timed out
  } else {
    throw error;
  }
}
```

#### Server streaming

Consider the following Protobuf definition:

```proto
service ExampleService {
  rpc ExampleStreamingMethod(ExampleRequest)
    returns (stream ExampleResponse) {};
}
```

Client method returns an Async Iterable:

```ts
for await (const response of client.exampleStreamingMethod(
  ExampleRequest.fromPartial({}),
)) {
  // ...
}
```

#### Client streaming

Given a client streaming method:

```proto
service ExampleService {
  rpc ExampleClientStreamingMethod(stream ExampleRequest)
    returns (ExampleResponse) {};
}
```

Client method expects an Async Iterable as its first argument:

```ts
async function* createRequest(): AsyncIterable<ExampleRequest> {
  for (let i = 0; i < 10; i++) {
    yield ExampleRequest.fromPartial({});
  }
}

const response = await client.exampleClientStreamingMethod(createRequest());
```

#### Middleware

Client middleware intercepts outgoing calls allowing to:

- Execute any logic before and after reaching server
- Modify request metadata
- Look into request, response and response metadata
- Send call multiple times for retries or hedging
- Augment call options type to have own configuration

Client middleware is defined as an Async Generator and is very similar to
[Server middleware](#middleware). Key differences:

- Middleware invocation order is reversed: middleware that is attached first,
  will be invoked last.
- There's no such thing as `CallContext` for client middleware; instead,
  `CallOptions` are passed through the chain and can be accessed or altered by a
  middleware.

To create a client with middleware, use a client factory:

```ts
import {createClientFactory} from 'nice-grpc';

const client = createClientFactory()
  .use(middleware1)
  .use(middleware2)
  .create(ExampleService, channel);
```

A middleware that is attached first, will be invoked last.

You can reuse a single factory to create multiple clients:

```ts
const clientFactory = createClientFactory().use(middleware);

const client1 = clientFactory.create(Service1, channel1);
const client2 = clientFactory.create(Service2, channel2);
```

You can also attach middleware per-client:

```ts
const factory = createClientFactory().use(middlewareA);

const client1 = clientFactory.use(middlewareB).create(Service1, channel1);
const client2 = clientFactory.use(middlewareC).create(Service2, channel2);
```

In the above example, `Service1` client gets `middlewareA` and `middlewareB`,
and `Service2` client gets `middlewareA` and `middlewareC`.

##### Example: Logging

Log all calls:

```ts
import {status} from '@grpc/grpc-js';
import {ClientMiddlewareCall, CallOptions, ClientError} from 'nice-grpc';
import {isAbortError} from 'abort-controller-x';

async function* loggingMiddleware<Request, Response>(
  call: ClientMiddlewareCall<Request, Response>,
  options: CallOptions,
) {
  const {path} = call.definition;

  console.log('Client call', path, 'start');

  try {
    const result = yield* call.next(call.request, options);

    console.log('Client call', path, 'end: OK');

    return result;
  } catch (error) {
    if (error instanceof ClientError) {
      console.log('Client call', path, `end: ${status[error.code]}`);
    } else if (isAbortError(error)) {
      console.log('Client call', path, 'cancel');
    } else {
      console.log('Client call', path, `error: ${error?.stack}`);
    }

    throw error;
  }
}
```

##### Example: Timeouts

Add support for specifying timeouts for unary calls instead of absolute
deadlines:

```ts
import ms = require('ms');
import {ClientMiddlewareCall, CallOptions} from 'nice-grpc';

type TimeoutCallOptionsExt = {
  /**
   * Examples: '10s', '1m'
   */
  timeout?: string;
};

async function* timeoutMiddleware<Request, Response>(
  call: ClientMiddlewareCall<Request, Response>,
  options: CallOptions & TimeoutCallOptionsExt,
) {
  const {timeout, ...nextOptions} = options;

  if (timeout != null && !call.requestStream && !call.responseStream) {
    nextOptions.deadline ??= new Date(Date.now() + ms(timeout));
  }

  return yield* call.next(call.request, nextOptions);
}
```

When creating a client, you can specify default call options for all methods, or
per-method:

```ts
const client = createClientFactory()
  .use(timeoutMiddleware)
  .create(ExampleService, channel, {
    '*': {
      timeout: '1m',
    },
    exampleUnaryMethod: {
      timeout: '30s',
    },
  });
```

Specify call options per-call:

```ts
await client.exampleUnaryMethod(ExampleRequest.fromPartial({}), {
  timeout: '15s',
});
```

[npm-image]: https://badge.fury.io/js/nice-grpc.svg
[npm-url]: https://badge.fury.io/js/nice-grpc
